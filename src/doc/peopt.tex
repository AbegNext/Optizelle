\documentclass{report}

% All of the packages required
\usepackage{amssymb}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{url}
\usepackage{subfig}
\usepackage{longtable}
\usepackage{amsmath}

% Change the figure numbering to be chap.sec.num
\renewcommand{\thefigure}{\arabic{chapter}.\arabic{section}.\arabic{figure}}

% Simple macros to help printing
\newcommand{\re}{\mathbb{R}}

% Create some new environments for displaying code and output
\lstdefinelanguage{peoptOutput}{
    morekeywords={Iter,f,x,merit,grad,dx,KryWhy,KryErr,KryIter,ared,pred,
        ared/pred,mu,mu_est,g},
    sensitive=false,
    literate=
}

\colorlet{punct}{red!60!black}
\definecolor{background}{HTML}{EEEEEE}
\definecolor{delim}{RGB}{20,105,176}
\colorlet{numb}{magenta!60!black}
\lstdefinelanguage{json}{
    basicstyle=\normalfont\ttfamily,
    stepnumber=1,
    numbersep=8pt,
    showstringspaces=false,
    breaklines=true,
    backgroundcolor=\color{background},
    literate=
     *{0}{{{\color{numb}0}}}{1}
      {1}{{{\color{numb}1}}}{1}
      {2}{{{\color{numb}2}}}{1}
      {3}{{{\color{numb}3}}}{1}
      {4}{{{\color{numb}4}}}{1}
      {5}{{{\color{numb}5}}}{1}
      {6}{{{\color{numb}6}}}{1}
      {7}{{{\color{numb}7}}}{1}
      {8}{{{\color{numb}8}}}{1}
      {9}{{{\color{numb}9}}}{1}
      {e-}{{{\color{numb}e-}}}{1}
      {:}{{{\color{punct}{:}}}}{1}
      {,}{{{\color{punct}{,}}}}{1}
      {\{}{{{\color{delim}{\{}}}}{1}
      {\}}{{{\color{delim}{\}}}}}{1}
      {[}{{{\color{delim}{[}}}}{1}
      {]}{{{\color{delim}{]}}}}{1},
}

\lstdefinestyle{C++}{
    language=C++,
    backgroundcolor=\color{black!5},
    showstringspaces=false,
    basicstyle=\footnotesize
} 

\lstdefinestyle{peoptOutput}{
    language=peoptOutput,
    backgroundcolor=\color{black!5},
    basicstyle=\scriptsize
}

\lstdefinestyle{json}{
    language=json,
    backgroundcolor=\color{black!5},
    basicstyle=\footnotesize
}

\title{Pretty Efficient Optimization (PEOpt)}
\author{Joseph Young}
\begin{document}
\maketitle
\tableofcontents

\chapter{Introduction}

        The PEOpt (\underline{P}retty \underline{E}fficient \underline{Opt}imization) library contains a collection of routines used to solve a variety of nonlinear optimization problems.  It focuses on open ended abstractions that make it easy to interface to existing applications.

\section{Unconstrained Optimization}

        The PEopt unconstrained optimization routines solve problems of the form
$$
        \min_{x\in X} f(x)
$$
where $f:X\rightarrow \re$ denotes a differentiable function.  For example, we formulate the minimization of the Rosenbrock function as
$$
        \min_{x\in\re^2} (1-x_1)^2+100(x_2-x_1^2)^2.
$$
In PEOpt, we minimize the Rosenbrock function with the code in Listing \ref{lst:Rosen} and the input specification in Listing \ref{lst:RosenJSON}, which generates the output in Listing \ref{lst:RosenOut}.  We explain the functions used to generate this example in Chapter \ref{ch:Basic}, the input specification in Chapter \ref{ch:Input}, and the output in Chapter \ref{ch:Output}.

\input{rosen_code.tex}
\input{rosen_input.tex}
\input{rosen_output.tex}

\section{Inequality Constrained Optimization}

        The PEopt inequality constrained optimization routines solve problems in the form
$$
        \min_{x\in X} \{ f(x) : h(x)\succeq 0\}
$$
where $f:X\rightarrow \re$ denotes a differentiable function, $h:X\rightarrow Z$ denotes an affine function, and $\succeq$ denotes a partial order that corresponds to a symmetric cone.  A symmetric cone includes inequalities such as pointwise inequalities, second-order cones, and semidefinite cones.  For example, these problems include linearly constrained quadratic programs such as
$$
        \min_{x\in\re^2}\{(x_1+1)^2+(x_2+1)^2 : x_1 + 2x_2 \geq 1, 2x_1 + x_2\geq 1\}
$$
In PEOpt, we minimize the above inequality constrained problem with the code in Listing \ref{lst:simpleIneq} and the input specification in Listing \ref{lst:simpleIneqJSON}, which generates the output in Listing \ref{lst:simpleIneqOut}.  As with the unconstrained example, we explain the functions used to generate this example in Chapter \ref{ch:Basic}, the input specification in Chapter \ref{ch:Input}, and the output in Chapter \ref{ch:Output}.

\input{simple_ineq_code.tex}
\input{simple_ineq_input.tex}
\input{simple_ineq_output.tex}

\section{Equality Constrained Optimization}

        The PEOpt equality constrained optimization routines solve problems in the form
$$
        \min_{x\in X} \{ f(x) : g(x)=0 \}
$$
where $f:X\rightarrow \re$ and $g:X\rightarrow Y$ denote differentiable functions.  For example, these problems include linearly constrained quadratic programs such as
$$
        \min_{x\in\re^2}\{x_1^2+x_2^2 : (x_1-2)^2 + (x_2-2)^2 = 1 \}
$$
In order to minimize this formulation in PEOpt, we use the code in Listing \ref{lst:simpleEq} and the input specification in Listing \ref{lst:simpleEqJSON}, which generates the output in Listing \ref{lst:simpleEqOut}.  Similar to the previous two examples, we explain the functions used to generate this example in Chapter \ref{ch:Basic}, the input specification in Chapter \ref{ch:Input}, and the output in Chapter \ref{ch:Output}.

\input{simple_eq_code.tex}
\input{simple_eq_input.tex}
\input{simple_eq_output.tex}

\section{Constrained Optimization}

        The PEOpt constrained optimization routines solve problems in the form
$$
        \min_{x\in X} \{ f(x) : g(x)=0, h(x)\succeq 0 \}
$$
where $f:X\rightarrow \re$ and $g:X\rightarrow Y$ denote differentiable functions, $h:X\rightarrow Z$ denotes an affine function, and $\succeq$ denotes a partial order that corresponds to a symmetric cone.  For example, these formulations include constrained problems such as 
$$
        \min_{x\in\re^2}\{(x_1+1)^2+(x_2+1)^2 :  x_1 + 2x_2 = 1, 2x_1 + x_2 \geq 1 \} 
$$
In order to minimize this formulation in PEOpt, we use the code in Listing \ref{lst:simpleCon} and the input specification in Listing \ref{lst:simpleConJSON}, which generates the output in Listing \ref{lst:simpleConOut}.  As with the other examples in the introduction, we explain the functions used to generate this example in Chapter \ref{ch:Basic}, the input specification in Chapter \ref{ch:Input}, and the output in Chapter \ref{ch:Output}.

\input{simple_con_code.tex}
\input{simple_con_input.tex}
\input{simple_con_output.tex}

\chapter{Installation}\label{ch:Install}

    Depending on the requirements of the application, PEOpt has several different build an installation methods.  In the most simple case, PEOpt can be incorporated into a project as a header taken from the source directory.  In a more complete case, PEOpt uses CMake in order to manage the installation of several supporting libraries.  We discuss these methods below.

        Outside the installation mechanism, there are two primary modes in which we access the PEOpt routines: headers only and as a library.  In headers only mode, PEOpt enables access to the core optimization and verification routines, which include utilities such as finite-difference tests.  In library mode, PEOpt also includes predefined vector spaces as well as parameter readers that read in parameter files in JSON format.

\section{Header Only Installation with No Build System}

        At its core, PEOpt requires two headers: \url{peopt.h} and \url{linalg.h} found in the \url{./src/cpp/peopt} directory.  Copy these files to a directory labeled \url{peopt} in the incorporating projects source tree.  Then, add the
\begin{verbatim}
#include <peopt/peopt.h>
\end{verbatim}
directive to the source files where PEOpt is used.


\section{Header Only Installation with CMake}

        In order to do a header only installation with CMake, we require CMake version 2.4 or better.  In the base PEOpt directory, execute the following commands
\begin{verbatim}
mkdir build
cd build
cmake -DCMAKE_INSTALL_PREFIX=/dir/to/install/location ../src
make install
\end{verbatim}
This installs the appropriate PEOpt headers to the directory \url{/dir/to/install/location/include/peopt}.

\section{Library Installation with CMake}

        In order to fully install PEOpt using CMake, we require CMake version 2.8.9 or better.  Then, in the base PEOpt directory, execute the following commands
\begin{verbatim}
mkdir build
cd build
ccmake ../src
make
make install
\end{verbatim}
The command \texttt{ccmake} executes the curses version of CMake, which displays several different options.  The PEOpt specific flags are
\begin{center}
\begin{longtable}{lp{0.75\textwidth}}
Flag:         &\texttt{ENABLE\_CPP\_LIBRARY}\\
Type:         &Bool\\
Default:      &Off\\
Dependencies: &\texttt{BLAS\_LIBRARY}, \texttt{LAPACK\_LIBRARY},
              \texttt{JSONCPP\_INCLUDE\_DIR}, \texttt{JSONCPP\_LIBRARY}\\
Autodetect?:  &No\\
Description:  &Enables the the library build for peopt.  This includes the
              built-in vector spaces for real vectors or cone programming.\\
\\
Flag:         &\texttt{ENABLE\_CPP\_EXAMPLES}\\
Type:         &Bool\\
Default:      &Off\\
Dependencies: &\texttt{ENABLE\_CPP\_LIBRARY}\\
Autodetect?:  &No\\
Description:  &Enables the build and installation of simple examples that
              demonstrate the use of peopt.  These examples are installed to
              the directory
              \url{${CMAKE_INSTALL_PREFIX}/share/peopt/cpp/examples}.\\
\\
Flag:         &\texttt{ENABLE\_CPP\_UNIT}\\
Type:         &Bool\\
Default:      &Off\\
Dependencies: &\texttt{ENABLE\_CPP\_LIBRARY},
              \texttt{BOOST\_UNIT\_TEST\_INCLUDE\_DIR},
              \texttt{BOOST\_UNIT\_TEST\_LIBRARY}\\
Autodetect?:  &No\\
Description:  &Enables the build and installation of unit tests that help
              validate the peopt code.  These tests are installed to the
              directory \url{${CMAKE_INSTALL_PREFIX}/share/peopt/cpp/unit}.\\
\\
Flag:         &\texttt{ENABLE\_OPENMP}\\
Type:         &Bool\\
Default:      &Off\\
Dependencies: &\texttt{ENABLE\_CPP\_LIBRARY}\\
Autodetect?:  &No\\
Description:  &Toggles whether or not the peopt library should be compiled
              using OpenMP.  This primarily affect whether or not the
              prepackaged vector spaces are coded to run in parallel using
              threads.\\
\\
Flag:         &\texttt{ENABLE\_PYTHON}\\
Type:         &Bool\\
Default:      &Off\\
Dependencies: &\texttt{ENABLE\_CPP\_LIBRARY}, \texttt{PYTHON\_INCLUDE\_DIR}, \texttt{PYTHON\_LIBRARY}\\
Autodetect?:  &No\\
Description:  &Enables the build and installation of the Python wrappers for
              peopt.  The resulting Python module is installed to
              \url{${CMAKE_INSTALL_PREFIX}/share/peopt/python}.  As such, make
              sure that the PYTHONPATH includes this directory.  In addition,
              using this module assumes that libpeopt\_complete.so can be found
              in the LD\_LIBRARY\_PATH.\\
\\
Flag:         &\texttt{ENABLE\_PYTHON\_EXAMPLES}\\
Type:         &Bool\\
Default:      &Off\\
Dependencies: &\texttt{ENABLE\_PYTHON\_LIBRARY}\\
Autodetect?:  &No\\
Description:  &Enables the build and installation of examples that use the
              Python wrappers for peopt.  These examples are installed into
              the directory
              \url{${CMAKE_INSTALL_PREFIX}/share/peopt/python/examples.}\\
\\
Flag:         &\texttt{ENABLE\_MATLAB}\\
Type:         &Bool\\
Default:      &Off\\
Dependencies: &\texttt{ENABLE\_CPP\_LIBRARY}, \texttt{MATLAB\_INCLUDE\_DIR},
              \texttt{MATLAB\_LIBRARY}, \texttt{MATLAB\_MEX\_EXTENSION}\\
Autodetect?:  &No\\
Description:  &Enables the build and installation of the MATLAB wrappers for
              peopt.  The resulting MATLAB mex file is installed to
              \url{${CMAKE_INSTALL_PREFIX}/share/peopt/matlab}.  As such, make
              sure that the MATLAB path includes this directory. \\
\\
Flag:         &\texttt{ENABLE\_MATLAB\_EXAMPLES}\\
Type:         &Bool\\
Default:      &Off\\
Dependencies: &\texttt{ENABLE\_MATLAB\_LIBRARY}\\
Autodetect?:  &No\\
Description:  &Enables the build and installation of examples that use the
              MATLAB wrappers for peopt.  These examples are installed into
              the directory
              \url{${CMAKE_INSTALL_PREFIX}/share/peopt/matlab/examples}.\\
\\
Flag:         &\texttt{BLAS\_LIBRARY} \\
Type:         &Path \\
Default:      &None \\
Dependencies: &\texttt{ENABLE\_CPP\_LIBRARY} \\
Autodetect?:  &Yes \\
Description:  &A semicolon separated list of the complete path and library used
              to provide BLAS.  This must include all required libraries in
              order to successfully compile a BLAS dependent application.  For
              example, using ATLAS BLAS, one possible entry is:
              \url{/usr/lib/libf77blas.a;/usr/lib/libatlas.a}\\
\\
Flag:         &\texttt{LAPACK\_LIBRARY} \\
Type:         &Path \\
Default:      &None \\
Dependencies: &\texttt{ENABLE\_CPP\_LIBRARY} \\
Autodetect?:  &Yes \\
Description:  &A semicolon separated list of the complete path and library used
              to provide LAPACK.  This must include all required libraries,
              except for BLAS libraries above in \texttt{BLAS\_LIBRARY}, in
              order to successfully compile a LAPACK dependent application.
              For example, using ATLAS LAPACK, one possible entry is:
              \url{/usr/lib/liblapack.a;/usr/lib/libcblas.a;/usr/lib/libgfortran.so.3}\\
\\
Flag:         &\texttt{BOOST\_UNIT\_TEST\_INCLUDE\_DIR} \\
Type:         &Path \\
Default:      &None \\
Dependencies: &\texttt{ENABLE\_CPP\_UNIT} \\
Autodetect?:  &Yes \\
Description:  &A path that indicates where the boost headers for unit testing
              have been installed.  The actual header must be found at
              \url{${BOOST_UNIT_TEST_INCLUDE_DIR}/boost/test/unit_test.hpp}.\\
\\
Flag:         &\texttt{BOOST\_UNIT\_TEST\_LIBRARY}\\
Type:         &Path \\
Default:      &None \\
Dependencies: &\texttt{ENABLE\_CPP\_UNIT}\\
Autodetect?:  &Yes \\
Description:  &The complete path and library for the boost unit test
              framework. \\
\\
Flag:         &\texttt{JSONCPP\_INCLUDE\_DIR} \\
Type:         &Path \\
Default:      &None \\
Dependencies: &\texttt{ENABLE\_CPP\_LIBRARY} \\
Autodetect?:  &Yes \\
Description:  &A path that indicates where the jsoncpp headers have been 
              installed.  The actual headers must be found in 
              \url{${JSONCPP_INCLUDE_DIR}/json/}.\\
\\
Flag:         &\texttt{JSONCPP\_LIBRARY}\\
Type:         &Path \\
Default:      &None \\
Dependencies: &\texttt{ENABLE\_CPP\_LIBRARY}\\
Autodetect?:  &Yes \\
Description:  &The complete path and library for jsoncpp. \\
\\
Flag:         &\texttt{PYTHON\_INCLUDE\_DIR} \\
Type:         &Path \\
Default:      &None \\
Dependencies: &\texttt{ENABLE\_PYTHON} \\
Autodetect?:  &Yes \\
Description:  &A path that indicates where the Python 2.7 headers have been 
              installed.  We do not prefix these headers, so we look directly
              in the directory provided here.\\
\\
Flag:         &\texttt{PYTHON\_LIBRARY}\\
Type:         &Path \\
Default:      &None \\
Dependencies: &\texttt{ENABLE\_PYTHON}\\
Autodetect?:  &Yes \\
Description:  &The complete path and library for Python 2.7. \\
\\
Flag:         &\texttt{MATLAB\_INCLUDE\_DIR} \\
Type:         &Path \\
Default:      &None \\
Dependencies: &\texttt{ENABLE\_MATLAB}\\
Autodetect?:  &Yes \\
Description:  &A path that indicates where the MATLAB headers have been 
              installed.  We do not prefix these headers, so we look directly
              in the directory provided here.\\
\\
Flag:         &\texttt{MATLAB\_LIBRARY}\\
Type:         &Path \\
Default:      &None \\
Dependencies: &\texttt{ENABLE\_MATLAB}\\
Autodetect?:  &Yes \\
Description:  &The complete path and library for the mex library.  Typically,
              this is libmex.so on Linux.\\
\\
Flag:         &\texttt{MATLAB\_MEX\_EXTENSION}\\
Type:         &String \\
Default:      &None \\
Dependencies: &\texttt{ENABLE\_MATLAB}\\
Autodetect?:  &No \\
Description:  &The extension of mex files on the system.  This can be found
              by typing in the command 'mexext' inside of MATLAB.  Note, copy
              the output from 'mexext' directly and do not add a '.'.
\end{longtable}
\end{center}
       
\chapter{Basic API}\label{ch:Basic}

       PEOpt organizes its algorithms into four different categories: unconstrained, inequality constrained, equality constrained, and constrained.  These categories correspond to the formulations
$$\begin{array}{l}
    \min\limits_{x\in X} f(x),\\
    \min\limits_{x\in X} \{ f(x) : h(x)\succeq 0\},\\
    \min\limits_{x\in X} \{ f(x) : g(x)=0 \},\\
    \min\limits_{x\in X} \{ f(x) : g(x)=0, h(x)\succeq 0 \},
\end{array}$$
respectively.  Since these formulations neccessitate different algorithms, the overall structure of PEOpt and the algorithms themselves have been segregated into these categories.

        In order to interface to optimize the above formulations, we follow the general procedure
\begin{enumerate}
    \item Define the objective function.
    \item (Optional) Define the constraints.
    \item Define an initial guess for the optimization.
    \item (Optional) Allocate memory for elements in the codomain of the constraints.  These are the Lagrange multipliers. 
    \item Create an optimization state.
    \item Set the optimization parameters.
    \item Accumulate all the functions required for optimization into a single bundle.
    \item Call the appropriate optimization routine.
    \item Extract the solution.
\end{enumerate}
We discuss how to implement each of the above steps below. 

\section{Define the Objective Function}

        PEOpt defines the objective function as a class that inherits from\linebreak\texttt{peopt::ScalarValuedFunction}, which PEOpt defines as
\input{objectiveSpecification.tex}
This specification corresponds to the evaluation of the objective, $f(x)$, gradient, $\nabla f(x)$, and Hessian-vector product, $\nabla^2 f(x)$, respectively.  Strictly, PEOpt only requires $f(x)$ and $\nabla f(x)$, but an appropriate first order method such as SR1 must be chosen when setting the optimization parameters.  In the case where the Hessian is not available, set the result of the Hessian vector product to zero. 

        As an example, we define the Rosenbrock function as
$$
        f(x)=(1-x_1)^2+100(x_2-x_1^2)^2.
$$
This means we define the gradient as
$$
        \nabla f(x)=\begin{bmatrix}
        -400x_1(x_2-x_1^2)-2(1-x_1)\\
        200(x_2-x_1^2)
        \end{bmatrix}
$$
and Hessian-vector product as
$$
        \nabla^2 f(x)\delta x=
        \begin{bmatrix}
            1200x_1^2-400x_2+2 & -400x_1\\
            -400x_1 & 200
        \end{bmatrix}\delta x.
$$
Using PEOpt's internal vector spaces, we implement these operators as
\input{objectiveExample.tex}

\section{Define the Constraints}

        PEOpt defines the constraints as a vector-valued function that inherits from \texttt{peopt::VectorValuedFunction}, which PEOpt defines as
\input{constraintSpecification.tex}
This abstract class corresponds to the evaluation of the constraint, $g(x)$, Fr\'{e}chet derivative (Jacobian)-vector product, $g^\prime(x)\delta x$, adjoint of the F\'{e}chet derivative (Jacobian)-vector product, $g^\prime(x)^*\delta y$, and the second derivative adjoint-vector product, $(g^{\prime\prime}(x)\delta x)^*\delta y$.  Here, $^*$ denotes the Hilbert-adjoint, which is most often the transpose of the operator.  Alternatively, if we work in $\re^m$ with the $\ell^2$ inner product, we can define these operators as
\begin{align*}
        g(x)&=\begin{bmatrix}
            g_1(x)\\
            \dots\\
            g_m(x)
        \end{bmatrix}
        & g^\prime(x)\delta x&=\begin{bmatrix}
                \nabla g_1(x)^T \delta x\\
                \dots\\
                \nabla g_m(x)^T \delta x
        \end{bmatrix}\\
        g^\prime(x)^*\delta y&=
        \sum\limits_{i=1}^m \nabla g_i(x) [\delta y]_i 
        & (g^{\prime\prime}(x)\delta x)^*\delta y&=
        \sum\limits_{i=1}^m \nabla^2 g_i(x)\delta x [\delta y]_i 
\end{align*}
As with the objective function, the algorithms in PEOpt do not require second order information, but benefit from it when available.  As such, the evaluation of $(g^{\prime\prime}(x)\delta x)^*\delta y$ is not strictly required.  If not available, set the result of the second derivative adjoint-vector product to zero.

        For example, we define a simple vector-valued function as
$$
    f(x)=\begin{bmatrix}
        (x_1-2)^2 + (x_2-2)^2 - 1\\
        x_1 + 2x_2 - 1.
    \end{bmatrix}
$$
Then, we have that
\begin{align*}
    f^\prime(x)\delta x=&\begin{bmatrix}
        2(x_1-2) & 2(x_2-2)\\
        1 & 2
    \end{bmatrix}\begin{bmatrix}\delta x_1\\\delta x_2\end{bmatrix}\\
    f^\prime(x)^*\delta y=&
        \begin{bmatrix}
            2(x_1-2)\\
            2(x_2-2)
        \end{bmatrix}  \delta y_1
        +
        \begin{bmatrix}
            1\\
            2
        \end{bmatrix} \delta y_2\\
    (f^{\prime\prime}(x)\delta x)^*\delta y=&
        \begin{bmatrix}
            2 & 0\\
            0 & 2
        \end{bmatrix}\begin{bmatrix}\delta x_1\\\delta x_2\end{bmatrix}
            \delta y_1
        +\begin{bmatrix}
            0 & 0\\
            0 & 0
        \end{bmatrix}\begin{bmatrix}\delta x_1\\\delta x_2\end{bmatrix}
            \delta y_2.
\end{align*}
In code, we implement these operators as
\input{constraintExample.tex}

\section{Define an Initial Guess} 

        The class \texttt{peopt::Rm} used in each of our examples defines an algebra for vectors in $\re^m$.  Underneith, the storage used for these vectors is simply a \texttt{std::vector}.  As such, we define our initial guess using this class.

        As an example, our initial guess for the Rosenbrock function was $\begin{bmatrix}-1.2 & 1\end{bmatrix}^T$.  We implement this in code as
\input{initialGuessExample.tex}

\section{Allocate Memory for Elements in the Codomain of the Constraints}

        As with our initial guess, we also use the class \texttt{peopt::Rm} to represent elements in the codomain of our constraints.  These elements correspond to the Lagrange multipliers or dual variables for the constrained algorithms, but, beyond label, we require no additional information about duality theory.  In addition, these elements are purely used for allocating memory.  This means that the value of these vectors when passed to PEOpt is ignored.

        For example, if we have a single equality constraint, we allocate memory for the codomain as
\input{allocateCodomainExample.tex}

\section{Create an Optimization State}

        In PEOpt, the optimization state contains an entire description of the current state of the optimization algorithm.  This is unique to the particular optimization formulation, but all algorithms in a particular formulations share the same state.  Most algorithms do not require information about all of these pieces, but they are present to make it easier to switch from one algorithm to another.  For example, trust-region and line-search algorithms share several components, but the trust-region radius is unique to trust-region algorithms and the line-search step length is unique to line-search algorithms.  Nevertheless, we may want to switch from one algorithm to another, so they share the same components.

        In order to define an optimization state, we instantiate the state class within the particular class of formulation we require.  The syntax is
\input{stateSpecification.tex}
  

\chapter{Input Specifications}\label{ch:Input}
\chapter{Output}\label{ch:Output}
\chapter{Advanced API}\label{ch:Advanced}

\end{document}
