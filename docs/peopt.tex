\documentclass{article}

\usepackage{listings}
\usepackage{amssymb}
\usepackage{amsmath}

\newcommand{\re}{\mathbb{R}}

\title{The peopt Reference Manual}
\author{Joseph Young}

\begin{document}
\lstset{language=C++}


\maketitle

\section{Introduction}

	The peopt (Parameter Estimation Using Optimization) library provides a collection of routines to implement a general purpose, matrix free, unconstrained optimization code.  In addition, it provides a series of operators used to quickly build the necessary components for a parameter estimation code.

\section{Core API}

	The following section describes the basic interface for the peopt code.  All routines may be accessed through {\texttt peopt.h}, which is itself split into {\texttt core.h} and {\texttt diff\_operator.h}.  The header file {\texttt core.h} contains the generic optimization routines and the header file {\texttt diff\_operator.h} contains building blocks for parameter estimation.  Both will be described below.

\subsection{Operator Specifications}

	The operator specifications provide an interface for a generic operator and functional.  We use these operators create a well-defined interface for operations such as the gradient or Hessian-vector products later.

\subsubsection{Operator}

\begin{flushleft}
\begin{lstlisting}
template <class Domain, class Codomain>
class Operator {
public:
    virtual void operator () (const Domain& x,Codomain &y)
	const = 0;
    virtual ~Operator() {}
};
\end{lstlisting}
\end{flushleft}

Defines a generic operator $A$ so that $y=A(x)$.  In addition, the destructor is left virtual in the likely case that a user specified operator needs to deallocate memory.

\subsubsection{Functional}

\begin{flushleft}
\begin{lstlisting}
template <class Domain>
class Functional {
public:
    virtual double operator () (const Domain& x) const = 0;
    virtual ~Functional() {}
};
\end{lstlisting}
\end{flushleft}

Defines a function $f$ so that $functional\leftarrow f(x)$.  In addition, the destructor is left virtual in the likely case that a user specified functional needs to deallocate memory.

\subsubsection{Operator/Functional}

\begin{flushleft}
\begin{lstlisting}
template <class Domain,class Codomain>
class OperatorFunctional : public Operator <Domain,Codomain> {
public:
    virtual void operator () (const Domain& x,Codomain &y,
	double &obj_val) const = 0;
    virtual ~OperatorFunctional() {}
};
\end{lstlisting}
\end{flushleft}

Defines both an operator $A$ and a function $f$ so that $y=A(x)$ and $functional\leftarrow f(x)$.  Most often, this is useful when two operations can be calculated simultaneously.  For example, in the context of parameter estimation, we can frequently calculate the objective function during the coarse of a gradient calculation.  In addition, the destructor is left virtual in the likely case that a user specified operator and functional need to deallocate memory.

\subsection{Algebraic Operations}

	The algebraic operations define the core set of routines required to implement an optimization algorithm.  The peopt library does not provide concrete implementations for these functions; they must be provided by the user.  Note, each of these functions lies in the namespace {\texttt Operations}.

\subsubsection{Scalar Multiplication}

\begin{flushleft}
\begin{lstlisting}
template <class Domain>
void scal(const double alpha,Domain& x);
\end{lstlisting}
\end{flushleft}

Defines the scalar multiplication operation $x\leftarrow \alpha x$. 

\subsubsection{Copy}

\begin{flushleft}
\begin{lstlisting}
template <class Domain>
void copy(const Domain& from, Domain& to);
\end{lstlisting}
\end{flushleft}

Defines the copy operation $to \leftarrow from$.  This assume that memory has already been allocated for both inputs and that $from$ and $to$ do not share memory for their storage.

\subsubsection{Addition}

\begin{flushleft}
\begin{lstlisting}
template <class Domain>
void axpy(const double alpha,const Domain& x,Domain& y);
\end{lstlisting}
\end{flushleft}

Defines the addition operation $y\leftarrow \alpha x+y$.

\subsubsection{Zeroing}

\begin{flushleft}
\begin{lstlisting}
template <class Domain>
void zero(Domain& x);
\end{lstlisting}
\end{flushleft}

Defines the zeroing operation $x\leftarrow 0$.  Most often, this can be accomplished by scaling an element by $0$.

\subsubsection{Inner Product}

\begin{flushleft}
\begin{lstlisting}
template <class Domain>
double innr(const Domain& x,const Domain& y);
\end{lstlisting}
\end{flushleft}

Defines the inner product operation $innr\leftarrow \langle x,y\rangle$.  This inner product can be anything appropriate for the problem.  For example, in $\re^m$, $\langle x,y\rangle=x^Ty$ suffices.  In $L^2(\Omega)$, $\langle x,y\rangle=\int_{\Omega} xy$.

\subsection{General Information/Constructs}

	The general information and constructs define a series of specification information in addition to a few routines generic to both line-search and trust-region methods, e.g. stopping criteria.  Each of these elements is defined in the namespace {\texttt General}. 

\subsubsection{Algorithm Class}

\begin{flushleft}
\begin{lstlisting}
enum AlgorithmClass{
    TrustRegion, 
    LineSearch
};
\end{lstlisting}
\end{flushleft}

Specifies whether or not we're working with a trust-region method or a line-search method.

\subsubsection{Krylov Stopping Conditions}

\begin{flushleft}
\begin{lstlisting}
enum KrylovStop{
  NegativeCurvature,        
  RelativeErrorSmall,      
  MaxKrylovItersExceeded,  
  TrustRegionViolated,    
};
\end{lstlisting}
\end{flushleft}

Specifies why the Krylov method terminated.  Typically, we use truncated conjugate gradient (truncated CG) as our underlying Krylov method for both line-search and trust-region methods.  In this context, we terminate the method when either we detect negative curvature, which can potentially occur when the Hessian is not positive, the relative error in current solution is small, we exceed a maximum number of Krylov iterations, or when we violate the trust-region radius.  Certainly, the last can not occur in the context of a line-search method.

\subsubsection{Optimization Stopping Conditions}

\begin{flushleft}
\begin{lstlisting}
enum StoppingCondition{
  NotConverged,            
  RelativeGradientSmall,    
  RelativeStepSmall,         
  MaxItersExceeded,           
};

template <class U>
StoppingCondition checkStop(
    const double norm_g,
    const double norm_gtyp,
    const double eps_g,
    const double norm_s,
    const double norm_styp,
    const double eps_d,
    const int iter,
    const int max_iter
);
\end{lstlisting}
\end{flushleft}

This routine determines whether or not the optimization should be terminated.  At the moment, there are three different stopping criteria.  First, we stop when the relative size of the gradient is small relative to some typical gradient,
$$
	\|g\|\leq \epsilon_g \|g_{typ}\|.
$$
Second, we stop when the relative size of a step is small with respect to some typical step,
$$
	\|s\|\leq \epsilon_d \|s_{typ}\|.
$$
Finally, we stop when we have exceeded a fixed number of iterations.  One easy estimate for the typical gradient and step is the gradient and step from the first iteration.

\subsection{Hessians and Approximations}

The following sections details information about Hessians and Hessian approximations provided by the library.  Each of these operators is defined in the namespace {\texttt Hessians}.

\subsubsection{Types of Hessians}

\begin{flushleft}
\begin{lstlisting}
enum Type{
    Identity_t,     
    ScaledIdentity_t,
    BFGS_t,          
    SR1_t,            
    GaussNewton_t      
};
\end{lstlisting}
\end{flushleft}

We implement five different kinds of Hessians and approximations: the identity, a scaled version of the identity, BFGS, SR1, and Gauss-Newton.  We explain each of these operators below.

\subsubsection{Identity}

\begin{flushleft}
\begin{lstlisting}
template <class U>
class Identity : public Operator <U,U>; 
\end{lstlisting}
\end{flushleft}

This implements the operator $A:U\rightarrow U$ so that $A(u)=u$.

\subsubsection{Scaled Identity}

\begin{flushleft}
\begin{lstlisting}
template <class U>
class ScaledIdentity : public Operator <U,U>;
ScaledIdentity(U& g_,double& delta_max_);
\end{lstlisting}
\end{flushleft}

This implements a scaled version of the identity.  Specifically, given $g$ and $\Delta_{max}$, this implements the operator $A:U\rightarrow U$ so that $A(u)=\|g\|/\Delta_{max} u$.  This operator is most useful when trying to implement steepest descent in trust-region methods.  If the gradient is very small, new iterates found by trust-region methods when using the identity operator are correspondingly small.  This means that very little progress is made toward optimality.  This occurs since truncated-CG exits prematurely since the error in the Krylov method appears to be small.  In order to prevent this behavior, we scale the identity operator.  In a line-search method, this is generally not required since the line-search takes care of the scaling issues.

\subsubsection{BFGS}

\begin{flushleft}
\begin{lstlisting}
template <class U>
class BFGS : public Operator <U,U>; 
BFGS(list <U>& oldY_,list <U>& oldS_,list <U>& work_);
\end{lstlisting}
\end{flushleft}

This implements a reduced-memory version of the BFGS operator.  In order to construct it, it requires three inputs.  First, we require a list of gradient residuals, $y_i=g_i-g_{i-1}$.  Second, we require a list of iterate residuals, $s_i=u_i-u_{i-1}$.  Finally, we require a work space that contains as many elements as both $y$ and $s$.  In terms of the implementation, this implements the {\it forward} BFGS operator using a recursive formulation.

\subsubsection{SR1}

\begin{flushleft}
\begin{lstlisting}
template <class U>
class SR1 : public Operator <U,U>; 
SR1(list <U>& oldY_,list <U>& oldS_,list <U>& work_);
\end{lstlisting}
\end{flushleft}

Similar to BFGS, this implements a reduced-memory version of the SR1 operator.  It has the same inputs as BFGS and also uses a recursively implementation.

\subsection{Preconditioners}

In the follow section, we discuss the preconditioners available in the package.  These preconditioners are used within truncated-CG, which is used in all trust-region methods and within Newton-CG.  All of these operators can be found in the namespace {\texttt Preconditioners}

\subsubsection{Types of Preconditioners}

\begin{flushleft}
\begin{lstlisting}
enum Type{      
    Identity_t,  
    BFGS_t,       
    SR1_t,
    External_t
};
\end{lstlisting}
\end{flushleft}

This enumerated type indicates that we can either use the identity, BFGS, SR1, or some externally defined preconditioner.

\subsubsection{Identity}

\begin{flushleft}
\begin{lstlisting}
template <class U>
class Identity : public Operator <U,U>; 
Identity();
\end{lstlisting}
\end{flushleft}

This implements the identity operator $A:U\rightarrow U$ where $A(u)=u$.  Essentially, with this option, we use no preconditioner.


\subsubsection{BFGS}

\begin{flushleft}
\begin{lstlisting}
template <class U>
class BFGS : public Operator <U,U>;
BFGS(list <U>& oldY_,list <U>& oldS_); 
\end{lstlisting}
\end{flushleft}

This implements the inverse of the BFGS operator.  Like the forward operator, it implements a reduced-memory BFGS using a recursive formulation.  However, unlike the forward operator, it does not require a workspace.

\subsubsection{SR1}

\begin{flushleft}
\begin{lstlisting}
template <class U>
class SR1 : public Operator <U,U>;
SR1(list <U>& oldY_,list <U>& oldS_,list <U>& work_); 
\end{lstlisting}
\end{flushleft}

This implements the inverse of the SR1 operator.  It uses the same signature as the forward operator.

\subsection{Trust-Region}

    The trust-region operations define a series of functions that allow the construction of algorithms based on trust-region globalization.  This includes operations such as truncated-CG as well as checking the predicted versus actual reduction.  Each of these routines are found under the \texttt{TrustRegion} namespace.

\subsubsection{Finding the Trust-Region Step}

\begin{flushleft}
\begin{lstlisting}
template <class U>
void getStep(
    Operator<U,U>& Minv,
    Operator<U,U>& H,
    const U& u,
    const U& g,
    const double delta,
    const int max_iter,
    const double eps_cg,
    list <U>& workU,
    U& s,
    double &rel_err,
    General::KrylovStop& why_stop,
    int &iter);
\end{lstlisting}
\end{flushleft}

This routine implements the truncated-CG (Steihaug-Toint) algorithm in an attempt to find a new optimization iterate that satisfies a trust-region constraint.  It, respectfully, requires a preconditioner $M^{-1}$, a Hessian approximation $H$, the current iterate $u$, the current gradient $g$, the size of the trust-region radius $\delta$, the maximum number of Krylov iterations allowable, a relative stopping tolerance for truncated-CG $\epsilon_{cg}$, a workplace with at least four elements.  Then, the routine returns a trial step $s$, the relative error in the solution to the trust-region problem, the reason why truncated-CG stopped computing, and the number of Krylov iterations that the routine computed.

\subsubsection{Checking the Trust-Region Step}

\begin{flushleft}
\begin{lstlisting}
void checkStep(
    const U& u,
    const U& s,
    const Functional<U>& obj_fn,
    const Operator<U,U>& H,
    const U& g,
    const double obj_u,
    const double eta1,
    const double eta2,
    const double delta_max,
    list <U>& workU,
    double& delta,
    bool& accept,
    double& obj_ups,
    double& rho);
\end{lstlisting}
\end{flushleft}

The above routine checks the actual reduction of a trial step and compares it to the predicted reduction.  In the context of a trust-region algorithm, if the ratio between the two is small, the step should be rejected.  Alternatively, if the ratio between the two is large, the step should be accepted.  Respectfully, the function inputs the current set of optimization parameters $u$, the trial step $s$, the objective function, the Hessian approximation $H$, the current gradient $g$, the current objective value, an acceptance tolerance $\eta_1$ where ratios between the predicted versus actual reduction imply that the step is rejected, an acceptance tolerance $\eta_2$ where ratios between the predicted versus actual reduction above this tolerance increase the size of the trust-region radius, a maximum trust-region radius $\delta_{max}$, a work space that contains at least two elements, and the current trust-region radius.  The function returns the current trust-region radius, whether or not the step should be accepted, the value of the objective function at $u+s$, and the predicted versus actual reduction.

\subsubsection{Stopping Conditions}

\begin{flushleft}
\begin{lstlisting}
enum StoppingCondition{
  NotConverged,               
  GradientSmall,             
  RelativeGradientSmall,    
  TrustRegionSmall,         
  RelativeTrustRegionSmall, 
  RelativeObjectiveSmall,   
  MaxItersExceeded,        
};

template <class U>
StoppingCondition checkStop(
    Operator <U,U>& Minv,
    const U& u,
    const U& g,
    const U& g_typ,
    const double obj_u,
    const double obj_ums,
    const double delta,
    const double eps_g,
    const double eps_d,
    const double eps_f,
    const double iter,
    const double max_iter,
    list <U>& workU);
\end{lstlisting}
\end{flushleft}

    This routine works in a similar manner to the \texttt{checkStop} routine found in the general section.  However, it includes four extra stopping conditions.  First, it checks whether the absolute size of the gradient is small,
$$
	\|g\|\leq \epsilon_g.
$$
Second, it checks whether the trust-region radius has become too small
$$
	\delta\leq \epsilon_d.
$$
Third, it checks whether the relative size of the trust-region radius is too small
$$
	\delta\leq\epsilon_d\|u\|.
$$
Fourth, it checks whether the relative difference in the objective function between iterations has become small
$$
	\frac{|J(u_{k+1})-J(u_k)|}{1+|J(u_k)|}\leq\epsilon_f.
$$

\subsection{Line-Search}

	The line-search routines provide a series of functions that allow the construction of algorithms based on line-search globalization.  This includes different search directions such as nonlinear CG, routines such as Newton-CG, and stopping conditions.  All of these routines are found within the \texttt{LineSearch} namespace.

\subsubsection{Stopping Conditions}

\begin{flushleft}
\begin{lstlisting}
enum StoppingCondition{
  NotConverged,               
  RelativeGradientSmall,     
  RelativeObjectiveSmall,   
  RelativeStepSmall,       
  MaxItersExceeded,       
};

template <class U>
StoppingCondition checkStop(
    const U& g,
    const U& g_typ,
    const double eps_g,
    const U& s,
    const U& s_typ,
    const double eps_d,
    const double obj_u,
    const double obj_ums,
    const double eps_f,
    const double iter,
    const double max_iter
);
\end{lstlisting}
\end{flushleft}

Similar to the trust-region stopping conditions, this routine duplicates many of the stopping conditions found within the general section.  It adds one additional stopping condition on the relative change in the objective value
$$
	\frac{|J(u_{k+1})-J(u_k)|}{1+|J(u_k)|}\leq\epsilon_f.
$$

\subsubsection{Search Direction}

\begin{flushleft}
\begin{lstlisting}
enum Directions{
  SteepestDescent_t,  
  FletcherReeves_t,   
  PolakRibiere_t,     
  HestenesStiefel_t,  
  BFGS_t,             
  NewtonCG_t         
};
\end{lstlisting}
\end{flushleft}

	Here, we define several different search directions that we describe below.  In short, we provide the steepest descent search direction in addition to three different varieties of nonlinear conjugate gradient.  These include Fletcher-Reeves, Polak-Ribiere, and Hestenes-Stiefel.  Finally, we also provide a routine that implements Newton-CG.

\subsubsection{Steepest Descent}

\begin{flushleft}
\begin{lstlisting}
template <class U>
void SteepestDescent(
    const U& g,
    U& s
);
\end{lstlisting}
\end{flushleft}
This implements the steepest descent search direction where
$$
	s=-\nabla J(u).
$$

\subsubsection{Nonlinear Conjugate Gradient}

\begin{flushleft}
\begin{lstlisting}
    template <class U>
    void FletcherReeves(
        const U& g,
        const U& g_old,
        const U& s_old,
        const bool first_iteration,
        U& s
    );

    template <class U>
    void PolakRibiere(
        const U& g,
        const U& g_old,
        const U& s_old,
        const bool first_iteration,
        U& s
    );

    template <class U>
    void HestenesStiefel(
        const U& g,
        const U& g_old,
        const U& s_old,
        const bool first_iteration,
        U& s
    );
\end{lstlisting}
\end{flushleft}

These routines implement different varieties of nonlinear conjugate gradient.  In general, each nonlinear CG algorithm implements a search direction of the form
$$
	s_k=\nabla J(u)+\beta s_{k-1}.
$$
The difference in the algorithms lies in the choice of $\beta$, the momentum parameter.  Here, we have
\begin{align*}
	\beta_{FR}&=\frac{\langle g_k,g_k\rangle}{\langle g_{k-1},g_{k-1}\rangle}\\
	\beta_{PR}&=\frac{\langle g_k,g_k-g_{k-1}\rangle}{\langle g_{k-1},g_{k-1}\rangle}\\
	\beta_{HS}&=\frac{\langle g_k,g_k-g_{k-1}\rangle}{\langle s_{k-1},g_k-g_{k-1}\rangle}
\end{align*}

\subsubsection{Limited Memory BFGS}

\begin{flushleft}
\begin{lstlisting}
template <class U>
void BFGS(
    Operator <U,U>& Hinv,
    const U& g,
    U& s
);
\end{lstlisting}
\end{flushleft}

	This function implements the limited memory BFGS algorithm.  It requires that $H^{-1}$ be the BFGS operator defined in the preconditioners section.

\subsubsection{Newton CG}
\begin{flushleft}
\begin{lstlisting}
template <class U>
void NewtonCG(
    Operator<U,U>& Minv,
    Operator<U,U>& H,
    const U& u,
    const U& g,
    const int max_iter,
    const double eps_cg,
    list <U>& workU,
    U& s,
    double &rel_err,
    General::KrylovStop& why_stop,
    int &iter);
\end{lstlisting}
\end{flushleft}

The \texttt{NewtonCG} function finds the Newton-CG search direction by applying truncated-CG to the specified Hessian approximation.  In general, it works very similarly to the \texttt{getStep} routine in the trust-region section.  It differs in that the computation has no knowledge of the trust-region radius.  In other words, it computes until either the maximum number of iterations is exceeded, negative curvature is detected, or the relative error in the solve becomes small. 

\subsubsection{Line Search Kind}

\begin{flushleft}
\begin{lstlisting}
enum SearchKind{    
  Brents_t,   
  TwoPointA_t, 
  TwoPointB_t
};
\end{lstlisting}
\end{flushleft}
We allow three different kinds of line-search.  The first is the traditional Brent's one dimensional minimization.  The second and third correspond to the nonmonotone line-search strategy developed by Barzilai and Borwein.  If this line-search is chosen, we require the search direction to be the steepest-descent search direction.

\section{Differentiable Operations and Parameter Estimation}

	The following section describes the operations used to quickly generate a code designed for parameter estimation.  Specifically, the code generates operators for the following parameter estimation problem
$$
	\min\limits_{u\in U} \sum\limits_{i=1}^m\frac{1}{2}\|r_i(h_i(u))\|^2
$$
where $r$ denotes the residual operator, $h$ denotes the solution operator, and $u$ denotes the unknown set of parameters.  In a simple case, the residual operator finds the difference between the current state solution and the experimental data.  In other words,
$$
	r(y)=y-d.
$$
The solution operator finds a state solution given a valid set of parameters.  For example, if the equation
$$
(A(u)+B)y=f
$$
describes a physical system, the function $h:U\rightarrow Y$ must satisfy the relationship
$$
(A(u)+B)h(u)=f.
$$
In general, $h$ does not need to find a strong solution of a particular equation.  Weak solutions suffice.

\subsection{Differentiable Operators}

\begin{flushleft}
\begin{lstlisting}
template <class Domain, class Codomain>
class DiffOperator {
public:
    virtual void operator () (const int i,const Domain& x,
	Codomain &y) const=0;

    virtual void p(const int i,const Domain& x,
	const Domain& eta,Codomain& y) const=0;

    virtual void ps(const int i,const Domain& x,
	const Codomain& xi,Domain& y) const=0;

    virtual void pps(const int i,const Domain& x,
	const Domain& eta, const Codomain& xi, Domain& y)
	const=0;

    virtual int max_index() const=0;
};
\end{lstlisting}
\end{flushleft}

The differentiable operator interface allows the user to specify both the residual and solution operators described above.  In addition, the user must provide routines that compute the directional derivative, the adjoint of the derivative, and the second derivative applied to a direction, adjoint, applied to a second direction.  For example, given the solution operator $h$ and a set of parameters $u$, the user must provide the operations
\begin{align*}
    &h_i(u)\\
    &h_i^\prime(u)\eta\\
    &h_i^\prime(u)^*\xi\\
    &(h_i^{\prime\prime}(u)\eta)^*\xi.
\end{align*}

\subsection{Hessian}

\begin{flushleft}
\begin{lstlisting}
    template <class Y,class U>
    class GaussNewton : public Operator <U,U>; 
    GaussNewton(
	const DiffOperator <Y,Y>& f_,
	const DiffOperator <U,Y>& h_,
	const U& u_,
	list <Y>& workY_,
	list <U>& workU_);

    template <class Y,class U>
    class Newton : public Operator <U,U>;
    Newton(
	const DiffOperator <Y,Y>& f_,
	const DiffOperator <U,Y>& h_,
	const U& u_,
	list <Y>& workY_,
	list <U>& workU_);
\end{lstlisting}
\end{flushleft}

These routines augment the Hessians namespace with the Gauss-Newton and Newton Hessian.  These operators are built automatically given the residual and solution operators.  In terms of work space, Gauss-Newton requires at least three work elements in the state space and one in the control.  Newton requires four work elements in the state space and a single in the control.

\subsection{Gradient}

\begin{flushleft}
\begin{lstlisting}
template <class Y,class U>
class getGradient: public Operator <U,U>;
getGradient(
    const DiffOperator <Y,Y>& f_,
    const DiffOperator <U,Y>& h_,
    list <Y>& workY_,
    list <U>& workU_); 
\end{lstlisting}
\end{flushleft}
Similar to the Hessian routines, the \texttt{getGradient} function augments the \texttt{General} name space and provides a routine that calculates the gradient of the parameter estimation problem.  In terms of work elements, this routine requires three elements in the state and one in the control space.

\subsection{Objective Function}

\begin{flushleft}
\begin{lstlisting}
template <class Y,class U>
class getObjValue : public Functional <U>; 
getObjValue(
    const DiffOperator <Y,Y>& f_,
    const DiffOperator <U,Y>& h_,
    list <Y>& workY_);
\end{lstlisting}
\end{flushleft}

The \texttt{getObjValue} function augments the \texttt{General} name space and provides a routine that calculates the objective function of the parameter estimation problem.  In terms of work space, it requires two elements in the state space.

\end{document}
